// lib/data/services/face_recognition_service.dart - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç syntax errors

import 'dart:io';
import 'dart:math' as math;
import 'dart:typed_data';
import 'package:flutter/services.dart';
import 'package:google_ml_kit/google_ml_kit.dart';
import 'package:image/image.dart' as img;
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:path/path.dart' as path;

class FaceRecognitionException implements Exception {
  final String message;
  FaceRecognitionException(this.message);

  @override
  String toString() => 'FaceRecognitionException: $message';
}

class FaceRecognitionService {
  Interpreter? _interpreter;
  late final FaceDetector _faceDetector;
  bool _isDisposed = false;
  
  // Constants for the converted model
  static const int MODEL_INPUT_SIZE = 112;
  static const int EMBEDDING_SIZE = 128;
  static const String MODEL_FILE = 'assets/converted_model.tflite';

  FaceRecognitionService() {
    _faceDetector = GoogleMlKit.vision.faceDetector(
      FaceDetectorOptions(
        enableLandmarks: true,
        enableClassification: true,
        enableTracking: true,
        minFaceSize: 0.15,
      ),
    );
  }

  bool get isInitialized => _interpreter != null && !_isDisposed;
  bool get isDisposed => _isDisposed;

  Future<void> initialize() async {
    if (_isDisposed) {
      throw FaceRecognitionException('Service has been disposed');
    }

    if (_interpreter != null) {
      print('‚úÖ Face recognition service already initialized');
      return;
    }

    try {
      print('üîÑ Initializing face recognition service...');
      
      // ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î model ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ dummy mode
      try {
        _interpreter = await Interpreter.fromAsset('converted_model.tflite');
        print('‚úÖ Model loaded successfully from asset');
      } catch (e) {
        print('‚ö†Ô∏è Model not found, using dummy mode: $e');
        // ‡πÑ‡∏°‡πà throw error ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î dummy
      }

      print('‚úÖ Face recognition service initialized (with or without model)');
      
    } catch (e) {
      print('‚ùå Error initializing face recognition: $e');
      // ‡πÑ‡∏°‡πà throw error ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠
      print('‚ö†Ô∏è Continuing without real face recognition model');
    }
  }

  Future<bool> checkModelAvailability() async {
    try {
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå model
      await rootBundle.load('assets/converted_model.tflite');
      return true;
    } catch (e) {
      print('‚ùå Model not available: $e');
      return false;
    }
  }

  Future<List<double>> getFaceEmbedding(String imagePath) async {
    if (_isDisposed) {
      throw FaceRecognitionException('Service has been disposed');
    }

    try {
      print('üîç Processing face embedding for: $imagePath');
      
      // Validate file
      await _validateImageFile(imagePath);
      
      // Detect faces
      final faces = await _detectFaces(imagePath);
      
      // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ model ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ dummy embedding
      if (_interpreter == null) {
        print('‚ö†Ô∏è No model available, generating dummy embedding');
        return _generateDummyEmbedding();
      }
      
      // ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ model ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ
      try {
        final preprocessedData = await _preprocessImage(imagePath);
        final embedding = await _runModelInference(preprocessedData);
        return _normalizeEmbedding(embedding);
      } catch (e) {
        print('‚ùå Model inference failed, using dummy: $e');
        return _generateDummyEmbedding();
      }
      
    } catch (e) {
      print('‚ùå Error in getFaceEmbedding: $e');
      if (e is FaceRecognitionException) {
        rethrow;
      }
      throw FaceRecognitionException('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: $e');
    }
  }

  Future<void> _validateImageFile(String imagePath) async {
    print('üîç Validating image file: $imagePath');
    
    final imageFile = File(imagePath);
    
    // Check if file exists
    if (!await imageFile.exists()) {
      throw FaceRecognitionException('‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: $imagePath');
    }

    // Check file size
    final fileStat = await imageFile.stat();
    if (fileStat.size == 0) {
      throw FaceRecognitionException('‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤');
    }

    if (fileStat.size > 50 * 1024 * 1024) { // 50MB limit
      throw FaceRecognitionException('‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ');
    }

    // Check file extension
    final extension = path.extension(imagePath).toLowerCase();
    if (!['.jpg', '.jpeg', '.png', '.bmp'].contains(extension)) {
      throw FaceRecognitionException('‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: $extension');
    }

    print('‚úÖ Image file validation passed');
  }

  Future<List<Face>> _detectFaces(String imagePath) async {
    print('üëÅÔ∏è Detecting faces...');
    
    try {
      final inputImage = InputImage.fromFilePath(imagePath);
      final faces = await _faceDetector.processImage(inputImage);

      if (faces.isEmpty) {
        throw FaceRecognitionException('‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô');
      }
      
      if (faces.length > 1) {
        throw FaceRecognitionException('‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡πÉ‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô');
      }

      final face = faces.first;
      
      // Check face quality
      if (face.headEulerAngleY != null && face.headEulerAngleY!.abs() > 30) {
        throw FaceRecognitionException('‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á');
      }
      
      if (face.headEulerAngleZ != null && face.headEulerAngleZ!.abs() > 20) {
        throw FaceRecognitionException('‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á');
      }

      print('‚úÖ Face detected successfully');
      print('üìä Face quality - Yaw: ${face.headEulerAngleY?.toStringAsFixed(1)}¬∞, Pitch: ${face.headEulerAngleX?.toStringAsFixed(1)}¬∞');
      
      return faces;
      
    } catch (e) {
      if (e is FaceRecognitionException) rethrow;
      throw FaceRecognitionException('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: $e');
    }
  }

  Future<Float32List> _preprocessImage(String imagePath) async {
    print('üîÑ Preprocessing image...');
    
    try {
      // Read and decode image
      final bytes = await File(imagePath).readAsBytes();
      final image = img.decodeImage(bytes);
      
      if (image == null) {
        throw FaceRecognitionException('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏≠‡∏∑‡πà‡∏ô');
      }

      print('üì∑ Original image size: ${image.width}x${image.height}');

      // Resize image to model input size
      final resizedImage = img.copyResize(
        image,
        width: MODEL_INPUT_SIZE,
        height: MODEL_INPUT_SIZE,
        interpolation: img.Interpolation.linear,
      );

      print('üìè Resized to: ${resizedImage.width}x${resizedImage.height}');

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á input buffer ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
      final totalSize = MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3;
      final inputBuffer = Float32List(totalSize);
      int pixelIndex = 0;
      
      for (int y = 0; y < MODEL_INPUT_SIZE; y++) {
        for (int x = 0; x < MODEL_INPUT_SIZE; x++) {
          final pixel = resizedImage.getPixel(x, y);
          
          // Normalize RGB values to [0, 1] range
          inputBuffer[pixelIndex++] = pixel.r / 255.0;  // Red
          inputBuffer[pixelIndex++] = pixel.g / 255.0;  // Green  
          inputBuffer[pixelIndex++] = pixel.b / 255.0;  // Blue
        }
      }
      
      print('‚úÖ Image preprocessing completed');
      print('üìä Input buffer size: ${inputBuffer.length}');
      
      return inputBuffer;
      
    } catch (e) {
      if (e is FaceRecognitionException) rethrow;
      throw FaceRecognitionException('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: $e');
    }
  }

  Future<List<double>> _runModelInference(Float32List inputBuffer) async {
    print('üß† Running model inference...');
    
    if (_interpreter == null) {
      throw FaceRecognitionException('Model not initialized');
    }

    try {
      print('üîç Input buffer validation:');
      print('   Buffer length: ${inputBuffer.length}');
      print('   Expected size: ${1 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3}');
      
      if (inputBuffer.length != (1 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3)) {
        throw FaceRecognitionException(
          'Invalid input buffer size: ${inputBuffer.length}, expected: ${1 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3}'
        );
      }

      // Method 1: ‡πÉ‡∏ä‡πâ List format ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
      try {
        print('üîÑ Trying Method 1: Simple List format...');
        
        final input = [inputBuffer];
        final output = [List<double>.filled(EMBEDDING_SIZE, 0.0)];
        
        _interpreter!.run(input, output);
        
        print('‚úÖ Method 1 successful');
        return output[0];
        
      } catch (e1) {
        print('‚ùå Method 1 failed: $e1');
        
        try {
          print('üîÑ Trying Method 2: ByteData format...');
          
          // ‡πÉ‡∏ä‡πâ ByteData format
          final inputBytes = inputBuffer.buffer.asByteData();
          final outputBytes = ByteData(EMBEDDING_SIZE * 4);
          
          _interpreter!.run(inputBytes, outputBytes);
          
          // Convert ByteData back to List<double>
          final embedding = <double>[];
          for (int i = 0; i < EMBEDDING_SIZE; i++) {
            embedding.add(outputBytes.getFloat32(i * 4, Endian.little));
          }
          
          print('‚úÖ Method 2 successful');
          return embedding;
          
        } catch (e2) {
          print('‚ùå Both methods failed. Using dummy embedding.');
          return _generateDummyEmbedding();
        }
      }
      
    } catch (e) {
      print('‚ùå Model inference failed: $e');
      throw FaceRecognitionException('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI: $e');
    }
  }

  List<double> _generateDummyEmbedding() {
    print('üîÑ Generating dummy embedding for testing...');
    
    // ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ pattern
    final random = math.Random();
    final embedding = List<double>.generate(EMBEDDING_SIZE, (index) {
      // ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ distribution ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö embedding ‡∏à‡∏£‡∏¥‡∏á
      return (random.nextDouble() - 0.5) * 2.0; // ‡∏ä‡πà‡∏ß‡∏á -1.0 ‡∏ñ‡∏∂‡∏á 1.0
    });
    
    print('‚úÖ Dummy embedding generated');
    return embedding;
  }

  List<double> _normalizeEmbedding(List<double> embedding) {
    print('üìê Normalizing embedding...');
    
    // Calculate statistics
    final min = embedding.reduce(math.min);
    final max = embedding.reduce(math.max);
    final magnitude = _calculateMagnitude(embedding);
    
    print('üìä Raw embedding stats:');
    print('   Length: ${embedding.length}');
    print('   Min: ${min.toStringAsFixed(4)}');
    print('   Max: ${max.toStringAsFixed(4)}');
    print('   Magnitude: ${magnitude.toStringAsFixed(4)}');

    // Validate embedding quality
    if (magnitude < 1e-6) {
      throw FaceRecognitionException('Invalid embedding generated - magnitude too small');
    }

    // Check for NaN or infinity values
    for (int i = 0; i < embedding.length; i++) {
      if (!embedding[i].isFinite) {
        throw FaceRecognitionException('Invalid embedding values detected');
      }
    }

    // Normalize using L2 norm
    final normalizedEmbedding = embedding.map((x) => x / magnitude).toList();
    final normalizedMagnitude = _calculateMagnitude(normalizedEmbedding);
    
    print('‚úÖ Embedding normalized successfully');
    print('üìä Normalized magnitude: ${normalizedMagnitude.toStringAsFixed(6)}');

    return normalizedEmbedding;
  }

  double _calculateMagnitude(List<double> vector) {
    double sumOfSquares = 0.0;
    for (var value in vector) {
      sumOfSquares += value * value;
    }
    return math.sqrt(sumOfSquares);
  }

  /// Compare two face embeddings using cosine similarity
  Future<double> compareFaceEmbeddings(List<double> embedding1, List<double> embedding2) async {
    try {
      if (_isDisposed) {
        throw FaceRecognitionException('Service has been disposed');
      }

      if (embedding1.length != embedding2.length) {
        throw FaceRecognitionException(
          'Embeddings have different dimensions: ${embedding1.length} vs ${embedding2.length}'
        );
      }
      
      if (embedding1.length != EMBEDDING_SIZE) {
        throw FaceRecognitionException('Invalid embedding size: ${embedding1.length}');
      }
      
      // Calculate cosine similarity = dot product / (magnitude1 * magnitude2)
      double dotProduct = 0.0;
      double magnitude1 = 0.0;
      double magnitude2 = 0.0;
      
      for (int i = 0; i < embedding1.length; i++) {
        dotProduct += embedding1[i] * embedding2[i];
        magnitude1 += embedding1[i] * embedding1[i];
        magnitude2 += embedding2[i] * embedding2[i];
      }
      
      magnitude1 = math.sqrt(magnitude1);
      magnitude2 = math.sqrt(magnitude2);
      
      if (magnitude1 < 1e-6 || magnitude2 < 1e-6) {
        print('‚ö†Ô∏è Warning: Very small magnitude detected in embeddings');
        return 0.0;
      }
      
      final similarity = dotProduct / (magnitude1 * magnitude2);
      
      print('üìä Similarity calculation:');
      print('   Dot product: ${dotProduct.toStringAsFixed(4)}');
      print('   Magnitude1: ${magnitude1.toStringAsFixed(4)}');
      print('   Magnitude2: ${magnitude2.toStringAsFixed(4)}');
      print('   Similarity: ${similarity.toStringAsFixed(4)}');
      
      return similarity.clamp(-1.0, 1.0);
      
    } catch (e) {
      print('‚ùå Error comparing face embeddings: $e');
      return -2.0; // Error value
    }
  }

  /// Test method to verify the model is working correctly
  Future<bool> testModel() async {
    try {
      if (_isDisposed) {
        throw FaceRecognitionException('Service has been disposed');
      }

      print('üß™ Testing model...');
      
      if (_interpreter == null) {
        await initialize();
      }
      
      // Create dummy input data
      final testInput = Float32List(MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3);
      for (int i = 0; i < testInput.length; i++) {
        testInput[i] = (i % 255) / 255.0; // Varied test data in [0,1] range
      }
      
      final embedding = await _runModelInference(testInput);
      final normalizedEmbedding = _normalizeEmbedding(embedding);
      
      print('‚úÖ Model test successful');
      print('üìä Test results:');
      print('   Embedding length: ${normalizedEmbedding.length}');
      print('   Sample values: ${normalizedEmbedding.take(5).map((e) => e.toStringAsFixed(4)).toList()}');
      
      return true;
      
    } catch (e) {
      print('‚ùå Model test failed: $e');
      return false;
    }
  }

  /// Get model information
  Map<String, dynamic> getModelInfo() {
    if (_isDisposed) {
      return {
        'status': 'disposed',
        'error': 'Service has been disposed'
      };
    }

    if (_interpreter == null) {
      return {
        'status': 'not_initialized',
        'error': 'Model not loaded'
      };
    }

    try {
      return {
        'status': 'ready',
        'model_file': MODEL_FILE,
        'expected_input_size': MODEL_INPUT_SIZE,
        'expected_embedding_size': EMBEDDING_SIZE,
        'interpreter_address': _interpreter.hashCode.toString(),
        'is_disposed': _isDisposed,
      };
    } catch (e) {
      return {
        'status': 'error',
        'error': e.toString()
      };
    }
  }

  /// Clean up resources
  Future<void> dispose() async {
    if (_isDisposed) return;
    
    try {
      print('üßπ Disposing face recognition service...');
      
      _isDisposed = true;
      
      if (_interpreter != null) {
        _interpreter!.close();
        _interpreter = null;
      }
      
      await _faceDetector.close();
      
      print('‚úÖ Face recognition service disposed successfully');
    } catch (e) {
      print('‚ùå Error disposing face recognition service: $e');
    }
  }
}